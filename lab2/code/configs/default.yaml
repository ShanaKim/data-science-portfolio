data:
  patch_size: 9
dataloader_train:
  batch_size: 8192
  num_workers: 4
  shuffle: True
dataloader_val:
  batch_size: 8192
  num_workers: 4
  shuffle: False
autoencoder:
  n_input_channels: 8
  embedding_size: 32
optimizer:
  lr: 0.001
trainer:
  max_epochs: 50
  log_every_n_steps: 50
checkpoint:
  save_top_k: 3
  monitor: 'val_loss'
  mode: 'min'
  filename: 'deeper_emb32-{epoch:03d}-{val_loss:.4f}'
  dirpath: 'checkpoints'
wandb:
  project: 'lab2-autoencoder'
  name: 'deeper_emb32'
