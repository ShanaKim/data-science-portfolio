{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from preprocessing import make_delayed\n",
    "from preprocessing import downsample_word_vectors\n",
    "\n",
    "# Add the root project folder to sys.path (so ridge_utils becomes importable)\n",
    "project_root = os.path.abspath('..')  # moves up from 'code/'\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "109\n",
      "dict_keys(['sweetaspie', 'thatthingonmyarm', 'tildeath', 'indianapolis', 'lawsthatchokecreativity', 'golfclubbing', 'jugglingandjesus', 'shoppinginchina', 'cocoonoflove', 'hangtime', 'beneaththemushroomcloud', 'dialogue4', 'thepostmanalwayscalls', 'stumblinginthedark', 'kiksuya', 'haveyoumethimyet', 'theinterview', 'againstthewind', 'tetris', 'canplanetearthfeedtenbillionpeoplepart2', 'alternateithicatom', 'goldiethegoldfish', 'seedpotatoesofleningrad', 'onapproachtopluto', 'canplanetearthfeedtenbillionpeoplepart1', 'bluehope', 'superheroesjustforeachother', 'howtodraw', 'myfirstdaywiththeyankees', 'thumbsup', 'avatar', 'mayorofthefreaks', 'gangstersandcookies', 'breakingupintheageofgoogle', 'forgettingfear', 'waitingtogo', 'firetestforlove', 'goingthelibertyway', 'thefreedomridersandme', 'exorcism', 'itsabox', 'inamoment', 'afearstrippedbare', 'swimmingwithastronauts', 'ifthishaircouldtalk', 'whenmothersbullyback', 'vixenandtheussr', 'adollshouse', 'catfishingstrangerstofindmyself', 'dialogue2', 'theshower', 'igrewupinthewestborobaptistchurch', 'thesurprisingthingilearnedsailingsoloaroundtheworld', 'odetostepfather', 'threemonths', 'theclosetthatateeverything', 'souls', 'reachingoutbetweenthebars', 'fromboyhoodtofatherhood', 'naked', 'treasureisland', 'penpal', 'gpsformylostidentity', 'adventuresinsayingyes', 'dialogue1', 'theadvancedbeginner', 'singlewomanseekingmanwich', 'dialogue5', 'undertheinfluence', 'leavingbaghdad', 'thetriangleshirtwaistconnection', 'lifeanddeathontheoregontrail', 'onlyonewaytofindout', 'comingofageondeathrow', 'legacy', 'canadageeseandddp', 'cautioneating', 'listo', 'thesecrettomarriage', 'googlingstrangersandkentuckybluegrass', 'christmas1940', 'birthofanation', 'quietfire', 'becomingindian', 'escapingfromadirediagnosis', 'wheretheressmoke', 'whyimustspeakoutaboutclimatechange', 'metsmagic', 'learninghumanityfromdogs', 'myfathershands', 'thecurse', 'findingmyownrescuer', 'food', 'eyespy', 'thetiniestbouquet', 'buck', 'wildwomenanddancingqueens', 'stagefright', 'afatherscover', 'marryamanwholoveshismother', 'backsideofthestorm', 'dialogue3', 'lifereimagined', 'dialogue6', 'mybackseatviewofagreatromance', 'notontheusualtour', 'canplanetearthfeedtenbillionpeoplepart3', 'life', 'sloth'])\n"
     ]
    }
   ],
   "source": [
    "# Load the raw_text.pkl file\n",
    "with open('/ocean/projects/mth240012p/shared/data/raw_text.pkl', 'rb') as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "print(type(raw_text)) #raw_text file is a dict \n",
    "print(len(raw_text)) # total 109 stories\n",
    "print(raw_text.keys()) #keys are names of the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'chunk_to_data_ind',\n",
       " 'chunkmeans',\n",
       " 'chunks',\n",
       " 'chunksums',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'data_times',\n",
       " 'data_to_chunk_ind',\n",
       " 'from_chunks',\n",
       " 'from_grid',\n",
       " 'mapdata',\n",
       " 'split_inds',\n",
       " 'tr_times']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see what's inside one story, 'penpal'\n",
    "dir(raw_text['penpal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', 'i', 'was', 'overseas', 'not', 'that', 'long', 'ago', 'on', 'a']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(raw_text['penpal'].data))\n",
    "print(len(raw_text['penpal'].data)) #total of 1592 words\n",
    "raw_text['penpal'].data[:10] #list of words from the stories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1592,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.23582766e-03, 1.24467120e+00, 1.49410431e+00, 2.00294785e+00,\n",
       "       2.41201814e+00, 2.59659864e+00, 2.83106576e+00, 3.17528345e+00,\n",
       "       3.71405896e+00, 4.08408275e+00, 4.30358388e+00, 4.38253968e+00,\n",
       "       4.60702948e+00, 4.95623583e+00, 5.34036281e+00, 5.62970522e+00,\n",
       "       5.91904762e+00, 6.29319728e+00, 6.56258503e+00, 7.25600907e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(raw_text['penpal'].data_times))\n",
    "print(raw_text['penpal'].data_times.shape) #vector\n",
    "raw_text['penpal'].data_times[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(270,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-9., -7., -5., -3., -1.,  1.,  3.,  5.,  7.,  9.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(raw_text['penpal'].tr_times))\n",
    "print(raw_text['penpal'].tr_times.shape) #how many FMRI scans per story\n",
    "raw_text['penpal'].tr_times[:10]\n",
    "#we can see that the FMRI shots were taken for 2 seconds each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 4, 10, 17, 23, 30, 36, 44, 48, 54, 61]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(raw_text['penpal'].split_inds))\n",
    "print(len(raw_text['penpal'].split_inds)) #list of indexes that shows where to split\n",
    "# list of words into word chunks\n",
    "# we can see that number of split indexes is one less than tr_times. \n",
    "raw_text['penpal'].split_inds[:15]\n",
    "#first five word chunks are empty. meaning first five FMRI scans were shot\n",
    "#before the story started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.896296296296296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1592/270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stories in the raw_text files are not in subejct 2 and 3. \n",
    "We exclude them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "all_stories = set(raw_text.keys())\n",
    "subj2_stories = set(os.path.splitext(f)[0] for f in os.listdir('/ocean/projects/mth240012p/shared/data/subject2') if f.endswith('.npy'))\n",
    "subj3_stories = set(os.path.splitext(f)[0] for f in os.listdir('/ocean/projects/mth240012p/shared/data/subject3') if f.endswith('.npy'))\n",
    "print(subj2_stories == subj3_stories) #fortunately, subject 2 and 3 has same stories\n",
    "valid_stories = sorted(list(all_stories & subj2_stories & subj3_stories))\n",
    "print(len(valid_stories)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue1',\n",
       " 'dialogue2',\n",
       " 'dialogue3',\n",
       " 'dialogue4',\n",
       " 'dialogue5',\n",
       " 'dialogue6',\n",
       " 'myfirstdaywiththeyankees',\n",
       " 'onlyonewaytofindout'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stories that are in the raw_text file but not in both of the subjects\n",
    "all_stories - set(valid_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we explore the npy files for subject 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (255, 94251)\n",
      "Data (preview): [[ 1.2453781  -0.41628303  0.40856305 ... -0.24667304 -0.04651232\n",
      "  -1.07498571]\n",
      " [ 0.08730935 -0.20358665 -0.26335135 ... -0.02177695 -1.43287916\n",
      "   0.43917887]\n",
      " [ 1.18076728  1.12036485  0.40589049 ... -0.41354723 -0.23335376\n",
      "  -0.9543282 ]\n",
      " [-0.08483419 -0.98204067  0.3281862  ...  0.18280717 -0.08003498\n",
      "  -0.22902656]\n",
      " [-0.01154614 -0.8344062  -0.02151216 ...  0.70086765  0.32259273\n",
      "   1.06684996]]\n"
     ]
    }
   ],
   "source": [
    "# Load the file for random story to explore data \n",
    "penpal_s2 = np.load('/ocean/projects/mth240012p/shared/data/subject2/penpal.npy')\n",
    "\n",
    "# Print basic info\n",
    "print(\"Type:\", type(penpal_s2))\n",
    "print(\"Shape:\", penpal_s2.shape)\n",
    "print(\"Data (preview):\", penpal_s2[:5])  # preview first 5 rows\n",
    "\n",
    "#255 time points (FMRI time steps while subject is listening to story 'penpal')\n",
    "#Each row has 94,251 values, which is the number of voxels (3D brain regions) measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (255, 95556)\n",
      "Data (preview): [[-0.38695819  0.13897068  1.08238927 ...  1.15880633  0.30080054\n",
      "   0.10387555]\n",
      " [ 1.62235331  0.12342972 -0.94471412 ... -0.95414812 -0.40348039\n",
      "   1.9248084 ]\n",
      " [-0.49907409 -0.18462957  0.13827181 ...  0.30105886  1.58567952\n",
      "   0.52668597]\n",
      " [-0.4617879   0.75625333  1.75015338 ... -2.12386876 -0.62403329\n",
      "   0.14806919]\n",
      " [-1.33391335 -0.64554708  1.54707993 ... -0.83972679  0.26833241\n",
      "   1.04564885]]\n"
     ]
    }
   ],
   "source": [
    "# Load the file for random story to explore data \n",
    "penpal_s3 = np.load('/ocean/projects/mth240012p/shared/data/subject3/penpal.npy')\n",
    "\n",
    "# Print basic info\n",
    "print(\"Type:\", type(penpal_s3))\n",
    "print(\"Shape:\", penpal_s3.shape)\n",
    "print(\"Data (preview):\", penpal_s3[:5])  # preview first 5 rows\n",
    "\n",
    "#255 time points (FMRI time steps while subject is listening to story)\n",
    "#Each row has 95,556 values, which is the number of voxels (brain regions) measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of voxels vary for subject 2 and 3, while the number of TRs for the same story is identical. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
